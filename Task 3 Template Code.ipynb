{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBC News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Exploratory Data Analytics\n",
    "###### (a) Load the dataset and construct a feature vector for each article in the. You need to report the number of articles, and the number of extracted features. Show 5 example articles with their extracted features using a dataframe.\n",
    "###### (b) Conduct term frequency analysis and report three plots: (i) top-50 term frequency distribution across the entire dataset, (ii) term frequency distribution for respective class of articles, and (iii) class distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ArticleId</th>\n      <th>Text</th>\n      <th>Category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1976</td>\n      <td>lifestyle governs mobile choice faster better ...</td>\n      <td>tech</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1797</td>\n      <td>french honour director parker british film dir...</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1866</td>\n      <td>fockers fuel festive film chart comedy meet fo...</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1153</td>\n      <td>housewives lift channel 4 ratings debut us tel...</td>\n      <td>entertainment</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>342</td>\n      <td>u2 desire number one u2 three prestigious gram...</td>\n      <td>entertainment</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  ArticleId                                               Text       Category\n0      1976  lifestyle governs mobile choice faster better ...           tech\n1      1797  french honour director parker british film dir...  entertainment\n2      1866  fockers fuel festive film chart comedy meet fo...  entertainment\n3      1153  housewives lift channel 4 ratings debut us tel...  entertainment\n4       342  u2 desire number one u2 three prestigious gram...  entertainment"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\", skiprows=0, header=0, na_values= \"\", dtype=str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method 1\n",
      "article vector\n",
      " [[0 1 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "article vector (5 articles)\n",
      " [[0 0 0 ... 0 0 1]\n",
      " [2 0 1 ... 0 0 0]\n",
      " [0 0 0 ... 2 0 0]\n",
      " [1 0 0 ... 0 1 0]\n",
      " [2 2 0 ... 0 0 0]]\n",
      "\n",
      " Method 2\n",
      "article vector\n",
      " [[0.         0.02011467 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "article vector (5 articles)\n",
      " [[0.         0.         0.         ... 0.         0.         0.05714108]\n",
      " [0.07651776 0.         0.05712739 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.10146309 0.         0.        ]\n",
      " [0.02856426 0.         0.         ... 0.         0.04265158 0.        ]\n",
      " [0.06048433 0.09031399 0.         ... 0.         0.         0.        ]]\n",
      "\n",
      "Articles: 428 , Extracted Features: 13518\n"
     ]
    }
   ],
   "source": [
    "articles_text = df[\"Text\"].to_numpy()\n",
    "\n",
    "#select 5 random articles for task 1\n",
    "random_sample = random.sample(list(articles_text), 5)\n",
    "\n",
    "## APPROACH ONE ##\n",
    "vectorizer1 = CountVectorizer()\n",
    "vectorizer1.fit(articles_text)\n",
    "\n",
    "vectorizer1_sample = CountVectorizer()\n",
    "vectorizer1_sample.fit(random_sample)\n",
    "\n",
    "#Summary\n",
    "#print(f'vector vocabulary - {vectorizer.vocabulary_}\\n')\n",
    "\n",
    "# encode document\n",
    "vector1 = vectorizer1.transform(articles_text)\n",
    "vector1_sample = vectorizer1_sample.transform(random_sample)\n",
    "\n",
    "# summarize encoded vector\n",
    "print(\"Method 1\")\n",
    "print(f'article vector\\n {vector1.toarray()}')\n",
    "print(f'\\narticle vector (5 articles)\\n {vector1_sample.toarray()}')\n",
    "\n",
    "## APPROACH TWO ##\n",
    "vectorizer2 = TfidfVectorizer()\n",
    "vectorizer2.fit(articles_text)\n",
    "\n",
    "vectorizer2_sample = TfidfVectorizer()\n",
    "vectorizer2_sample.fit(random_sample)\n",
    "\n",
    "#Summary\n",
    "#print(f'vector vocabulary - {vectorizer.vocabulary_}\\n')\n",
    "\n",
    "# encode document\n",
    "vector2 = vectorizer2.transform(articles_text)\n",
    "vector2_sample = vectorizer2_sample.transform(random_sample)\n",
    "\n",
    "# summarize encoded vector\n",
    "print('\\n', \"Method 2\")\n",
    "print(f'article vector\\n {vector2.toarray()}')\n",
    "print(f'\\narticle vector (5 articles)\\n {vector2_sample.toarray()}')\n",
    "print('\\nArticles:', vector2.shape[0], ', Extracted Features:', vector2.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this code for Task 3(a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.1_train</th>\n      <th>0.3_train</th>\n      <th>0.5_train</th>\n      <th>0.7_train</th>\n      <th>0.9_train</th>\n      <th>0.1_test</th>\n      <th>0.3_test</th>\n      <th>0.5_test</th>\n      <th>0.7_test</th>\n      <th>0.9_test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>LR</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>NB</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>SVM</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>NN</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "    0.1_train 0.3_train 0.5_train 0.7_train 0.9_train 0.1_test 0.3_test  \\\nLR          0         0         0         0         0        0        0   \nNB          0         0         0         0         0        0        0   \nSVM         0         0         0         0         0        0        0   \nNN          0         0         0         0         0        0        0   \n\n    0.5_test 0.7_test 0.9_test  \nLR         0        0        0  \nNB         0        0        0  \nSVM        0        0        0  \nNN         0        0        0  "
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import floor\n",
    "\n",
    "m = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "training_output = pd.DataFrame(columns=m)\n",
    "testing_output = pd.DataFrame(columns=m)\n",
    "\n",
    "NUM_ARTICLES = vector1.shape[0]\n",
    "\n",
    "# LOGISTIC REGRESSION\n",
    "training_accuracies = {}\n",
    "testing_accuracies = {}\n",
    "for m_value in m:\n",
    "    TRAIN_LENGTH = floor(m_value * NUM_ARTICLES)\n",
    "    VECTOR_ARRAY = vector1.toarray() # change this to vector 2 if needed\n",
    "    X_train = VECTOR_ARRAY[0:TRAIN_LENGTH]\n",
    "    X_test = VECTOR_ARRAY[TRAIN_LENGTH:]\n",
    "    Y_train = df[\"Category\"].to_list()[:TRAIN_LENGTH]\n",
    "    Y_test = df[\"Category\"].to_list()[TRAIN_LENGTH:]\n",
    "\n",
    "    # train your model here\n",
    "\n",
    "    # put your accuracy calc here\n",
    "    training_accuracies[m_value] = 0\n",
    "    testing_accuracies[m_value] = 0\n",
    "\n",
    "training_output = pd.concat(objs=[training_output, pd.DataFrame(training_accuracies, index=['LR'])])\n",
    "testing_output = pd.concat(objs=[testing_output, pd.DataFrame(testing_accuracies, index=['LR'])])\n",
    "\n",
    "# NAIVE BAYES\n",
    "training_accuracies = {}\n",
    "testing_accuracies = {}\n",
    "for m_value in m:\n",
    "    TRAIN_LENGTH = floor(m_value * NUM_ARTICLES)\n",
    "    VECTOR_ARRAY = vector1.toarray() # change this to vector 2 if needed\n",
    "    X_train = VECTOR_ARRAY[0:TRAIN_LENGTH]\n",
    "    X_test = VECTOR_ARRAY[TRAIN_LENGTH:]\n",
    "    Y_train = df[\"Category\"].to_list()[:TRAIN_LENGTH]\n",
    "    Y_test = df[\"Category\"].to_list()[TRAIN_LENGTH:]\n",
    "\n",
    "    # train your model here\n",
    "\n",
    "    # put your accuracy calc here\n",
    "    training_accuracies[m_value] = 0\n",
    "    testing_accuracies[m_value] = 0\n",
    "    \n",
    "training_output = pd.concat(objs=[training_output, pd.DataFrame(training_accuracies, index=['NB'])])\n",
    "testing_output = pd.concat(objs=[testing_output, pd.DataFrame(testing_accuracies, index=['NB'])])\n",
    "\n",
    "# SVM\n",
    "training_accuracies = {}\n",
    "testing_accuracies = {}\n",
    "for m_value in m:\n",
    "    TRAIN_LENGTH = floor(m_value * NUM_ARTICLES)\n",
    "    VECTOR_ARRAY = vector1.toarray() # change this to vector 2 if needed\n",
    "    X_train = VECTOR_ARRAY[0:TRAIN_LENGTH]\n",
    "    X_test = VECTOR_ARRAY[TRAIN_LENGTH:]\n",
    "    Y_train = df[\"Category\"].to_list()[:TRAIN_LENGTH]\n",
    "    Y_test = df[\"Category\"].to_list()[TRAIN_LENGTH:]\n",
    "\n",
    "    # train your model here\n",
    "\n",
    "    # put your accuracy calc here\n",
    "    training_accuracies[m_value] = 0\n",
    "    testing_accuracies[m_value] = 0\n",
    "    \n",
    "training_output = pd.concat(objs=[training_output, pd.DataFrame(training_accuracies, index=['SVM'])])\n",
    "testing_output = pd.concat(objs=[testing_output, pd.DataFrame(testing_accuracies, index=['SVM'])])\n",
    "\n",
    "# Not Nearest Neighbour (lol)\n",
    "training_accuracies = {}\n",
    "testing_accuracies = {}\n",
    "for m_value in m:\n",
    "    TRAIN_LENGTH = floor(m_value * NUM_ARTICLES)\n",
    "    VECTOR_ARRAY = vector1.toarray() # change this to vector 2 if needed\n",
    "    X_train = VECTOR_ARRAY[0:TRAIN_LENGTH]\n",
    "    X_test = VECTOR_ARRAY[TRAIN_LENGTH:]\n",
    "    Y_train = df[\"Category\"].to_list()[:TRAIN_LENGTH]\n",
    "    Y_test = df[\"Category\"].to_list()[TRAIN_LENGTH:]\n",
    "\n",
    "    # train your model here\n",
    "\n",
    "    # put your accuracy calc here\n",
    "    training_accuracies[m_value] = 0\n",
    "    testing_accuracies[m_value] = 0\n",
    "    \n",
    "training_output = pd.concat(objs=[training_output, pd.DataFrame(training_accuracies, index=['NN'])])\n",
    "testing_output = pd.concat(objs=[testing_output, pd.DataFrame(testing_accuracies, index=['NN'])])\n",
    "\n",
    "pd.merge(training_output, testing_output, left_index=True, right_index=True, suffixes=('_train', '_test'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3912jvsc74a57bd0e838a97a291bc2acdc6b43010bdfa08f2539f141d5ae0582ea8a95f5e4b22b08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}